{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second part of the project, the objective is to build an n-gram language model that is defined by the probabilities of all the n-grams in the corpus. Assuming that each token only depends on n-1 previous tokens, the language model is fully defined by the probability of any token in the corpus given its n-1 previous tokens (the prefix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import operator\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are imported, the dataset was cleaned in the script Clean_dataset.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(779478, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         post_id  parent_id  comment_id  \\\n",
       "0             1        NaN         NaN   \n",
       "1             3        NaN         NaN   \n",
       "2             4        NaN         NaN   \n",
       "3             6        NaN         NaN   \n",
       "4             7        NaN         NaN   \n",
       "...         ...        ...         ...   \n",
       "779473   279994        NaN    536471.0   \n",
       "779474   279998        NaN    536439.0   \n",
       "779475   279998        NaN    536514.0   \n",
       "779476   279999        NaN    536802.0   \n",
       "779477   279999        NaN    542550.0   \n",
       "\n",
       "                                                     text category  \\\n",
       "0                           Eliciting priors from experts    title   \n",
       "1       What are some valuable Statistical Analysis op...    title   \n",
       "2       Assessing the significance of differences in d...    title   \n",
       "3       The Two Cultures: statistics vs. machine learn...    title   \n",
       "4                  Locating freely available data samples    title   \n",
       "...                                                   ...      ...   \n",
       "779473  It does run, and gives very valid looking esti...  comment   \n",
       "779474  It seems to me that you are correct; the doubl...  comment   \n",
       "779475  It wouldn't be the first time a grader has mis...  comment   \n",
       "779476  The basic idea is to compare the clustering co...  comment   \n",
       "779477  As per your other question, your data does not...  comment   \n",
       "\n",
       "                                            cleaned_texts  \n",
       "0                           eliciting priors from experts  \n",
       "1       what are some valuable statistical analysis op...  \n",
       "2       assessing the significance of differences in d...  \n",
       "3       the two cultures : statistics vs. machine lear...  \n",
       "4                  locating freely available data samples  \n",
       "...                                                   ...  \n",
       "779473  it does run , and gives very valid looking est...  \n",
       "779474  it seems to me that you are correct ; the doub...  \n",
       "779475  it would be the first time a grader has missed...  \n",
       "779476  the basic idea is to compare the clustering , ...  \n",
       "779477  as per your other question , your data does no...  \n",
       "\n",
       "[779478 rows x 6 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data in training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = data[data['category'] == \"title\"]\n",
    "train_set = data[data['category'].isin([\"comment\", \"post\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(693040, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The texts are padded with a start and end symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> how should i elicit prior distributions from experts when fitting a bayesian model ? </s>',\n",
       " '<s> in many different statistical methods there is an assumption of normality . what is normality and how do i know if there is normality ? </s>',\n",
       " '<s> what are some valuable statistical analysis open source projects available right now ? edit : as pointed out by sharpie , valuable could mean helping you get things done faster or more cheaply . </s>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = train_set['cleaned_texts']\n",
    "texts = [f\"<s> {text} </s>\" for text in texts]\n",
    "\n",
    "texts[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split texts in trigrams\n",
    "n = 3\n",
    "tri_grams = [list(ngrams(sentence.split(), n)) for sentence in texts]\n",
    "tri_grams = [tri_gram for trigram_list in tri_grams for tri_gram in trigram_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a count dict for trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "\n",
    "for first, second, third in tri_grams:\n",
    "    count_dict[(first, second)][third] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a probability dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dict = collections.defaultdict(lambda: collections.defaultdict(float))\n",
    "\n",
    "for bi_key, value in count_dict.items():\n",
    "    sum_values = sum(value.values())\n",
    "    for third, count in value.items():\n",
    "        prob_dict[bi_key][third] = count / sum_values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function generate_text takes a bigram and the prob_dict as input and produces text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prob_dict, bi_gram):\n",
    "    bi_gram_dict = prob_dict[bi_gram]\n",
    "    most_probable = max(bi_gram_dict.items(), key=operator.itemgetter(1))[0]\n",
    "    \n",
    "    return most_probable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shall', 'we', 'presume', 'that', 'the', 'data', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "start_of_text_list = ['shall', 'we']\n",
    "\n",
    "while len(start_of_text_list) < 100:\n",
    "    \n",
    "    input_tuple = (start_of_text_list[-2], start_of_text_list[-1])\n",
    "    new_word = generate_text(prob_dict, input_tuple)\n",
    "    start_of_text_list.append(new_word)\n",
    "    \n",
    "    if new_word == '</s>':\n",
    "        break\n",
    "        \n",
    "print(start_of_text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function sentence_prob calculates the probability of a whole sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2065397568632802e-12"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_prob(prob_dict, sentence, n):\n",
    "    tri_grams = list(ngrams(sentence.split(), n))\n",
    "    \n",
    "    sentence_probability = 0\n",
    "    for first, second, third in tri_grams:\n",
    "        tri_gram_prob = prob_dict[(first, second)][third]\n",
    "        sentence_probability += np.log(tri_gram_prob)\n",
    "        \n",
    "    sentence_probability = np.exp(sentence_probability)\n",
    "        \n",
    "    \n",
    "    return sentence_probability\n",
    "\n",
    "test_sen = \"this does not go as it should go .\"\n",
    "sentence_prob(prob_dict, test_sen, n)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.099547981469296"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_perplexity(sentence):\n",
    "    \n",
    "    sentence_length = len(sentence.split())\n",
    "    \n",
    "    prob_of_sentence = sentence_prob(prob_dict, sentence, n)\n",
    "    perplexity = prob_of_sentence**(-1/sentence_length)\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "sentence_perplexity(test_sen)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
